{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_random(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = preds.flatten()\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sequence from a language model\n",
    "def generate_seq(model, tokenizer, max_length, seed_text, randomness, n_words):\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "        # encode the text as integer\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # pre-pad sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
    "        # predict probabilities for each word\n",
    "        yhat = model.predict(encoded, verbose=0)\n",
    "        yhat = pick_random(yhat, randomness)\n",
    "        # map predicted word index to word\n",
    "        out_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == yhat:\n",
    "                out_word = word\n",
    "                break\n",
    "        # append to input\n",
    "        in_text += ' ' + out_word\n",
    "    return in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2341607\n"
     ]
    }
   ],
   "source": [
    "# source text\n",
    "data = \"\"\n",
    "with open(\"../../WAFiles/blogs.txt\", 'r') as fin:\n",
    "    #for line in fin:\n",
    "    #    data += line\n",
    "    \n",
    "    for i in range(2000):\n",
    "        data += fin.readline()\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 21434\n"
     ]
    }
   ],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])\n",
    "encoded = tokenizer.texts_to_sequences([data])[0]\n",
    "# retrieve vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocabulary Size: %d' % vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.09\n",
      "46.19\n",
      "69.28\n",
      "92.38\n",
      "Total Sequences: 433014\n"
     ]
    }
   ],
   "source": [
    "# encode 2 words -> 1 word\n",
    "\n",
    "sequences = list()\n",
    "for i in range(2, len(encoded)):\n",
    "    if i%100000==0:\n",
    "        print(\"%.2f\" % (i / len(encoded) * 100))\n",
    "    sequence = encoded[i-2:i+1]\n",
    "    sequences.append(sequence)\n",
    "print('Total Sequences: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sequence Length: 3\n"
     ]
    }
   ],
   "source": [
    "# pad sequences\n",
    "\n",
    "max_length = max([len(seq) for seq in sequences])\n",
    "sequences = pad_sequences(sequences, maxlen=max_length, padding='pre')\n",
    "print('Max Sequence Length: %d' % max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input and output elements\n",
    "\n",
    "sequences = array(sequences)\n",
    "X, y = sequences[:,:-1],sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=vocab_size, dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yixuan/miniconda3/envs/mlgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yixuan/miniconda3/envs/mlgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yixuan/miniconda3/envs/mlgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 2, 64)             1371776   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 1024)              4460544   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 21434)             10995642  \n",
      "=================================================================\n",
      "Total params: 17,352,762\n",
      "Trainable params: 17,352,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /home/yixuan/miniconda3/envs/mlgpu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yixuan/miniconda3/envs/mlgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 64, input_length=max_length-1))\n",
    "model.add(LSTM(1024))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())\n",
    "# compile network\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yixuan/miniconda3/envs/mlgpu/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/yixuan/miniconda3/envs/mlgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Epoch 1/10\n",
      "433014/433014 [==============================] - 168s 389us/step - loss: 6.3089 - acc: 0.0958\n",
      "Epoch 2/10\n",
      "433014/433014 [==============================] - 166s 383us/step - loss: 5.7215 - acc: 0.1294\n",
      "Epoch 3/10\n",
      "433014/433014 [==============================] - 169s 390us/step - loss: 5.4092 - acc: 0.1436\n",
      "Epoch 4/10\n",
      "433014/433014 [==============================] - 167s 386us/step - loss: 5.1608 - acc: 0.1558\n",
      "Epoch 5/10\n",
      "433014/433014 [==============================] - 168s 389us/step - loss: 4.9412 - acc: 0.1676\n",
      "Epoch 6/10\n",
      "433014/433014 [==============================] - 162s 375us/step - loss: 4.7356 - acc: 0.1797\n",
      "Epoch 7/10\n",
      "433014/433014 [==============================] - 161s 371us/step - loss: 4.5409 - acc: 0.1922\n",
      "Epoch 8/10\n",
      "433014/433014 [==============================] - 162s 375us/step - loss: 4.3561 - acc: 0.2050\n",
      "Epoch 9/10\n",
      "433014/433014 [==============================] - 163s 377us/step - loss: 4.1793 - acc: 0.2193\n",
      "Epoch 10/10\n",
      "433014/433014 [==============================] - 161s 371us/step - loss: 4.0109 - acc: 0.2345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa3ce9b7410>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit network\n",
    "model.fit(X, y, batch_size=64, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "today i went to the point of course i don't know i just want to go to the doctor and i was just a little bit i got to go to the dean is great i think i might have to go to sleep but i don't know i don't know what i think i need to go to the park was a lot of fun i think i may have been a little bit i have a lot of fun i went to the owner design visitors and drew all over again and i have to go to sleep in the\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "print(generate_seq(model, tokenizer, max_length-1, \"today i\", 0.3, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(tokenizer, open('tokenizer_216.dat', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
