{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import string\n",
    "import collections\n",
    "\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_random(preds, temperature=1.0):\n",
    "    #helper function to sample an index from a probability array\n",
    "    preds = preds.flatten()\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "punc = string.punctuation\n",
    "\n",
    "# generate a sequence from a language model\n",
    "def generate_seq(model, max_length, seed_text, randomness, n_words):\n",
    "    in_text = seed_text\n",
    "    print(in_text, end=\"\")\n",
    "    # generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "        # encode the text as integer\n",
    "        encoded = tokenNL(in_text)\n",
    "        # pre-pad sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
    "        # predict probabilities for each word\n",
    "        yhat = model.predict(encoded, verbose=0)\n",
    "        yhat = pick_random(yhat[0], randomness)\n",
    "        \n",
    "        out_word = tokenW(yhat)\n",
    "        \n",
    "        ispunc = True\n",
    "        for c in out_word:\n",
    "            if not c in punc:\n",
    "                ispunc = False\n",
    "                break\n",
    "        \n",
    "        # append to input\n",
    "        in_text += ' ' + out_word\n",
    "        print(('' if ispunc else ' ') + out_word, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98295231\n",
      "10655598\n"
     ]
    }
   ],
   "source": [
    "# source text\n",
    "train = \"\"\n",
    "test = \"\"\n",
    "with open(\"../../WAFiles/blogs.txt\", 'r') as fin:\n",
    "    #for line in fin:\n",
    "    #    data += line\n",
    "    \n",
    "    for i in range(100000):\n",
    "        train += fin.readline()\n",
    "    for i in range(10000):\n",
    "        test += fin.readline()\n",
    "\n",
    "train = train.lower()\n",
    "test = test.lower()\n",
    "        \n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainl = train.split()\n",
    "trainc = collections.Counter(trainl)\n",
    "trainlist = [i for i in trainc.keys() if trainc[i] >= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in trainc.keys():\n",
    "#     if trainc[i] == 2:\n",
    "#         print(i)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79113\n"
     ]
    }
   ],
   "source": [
    "trainsplit = train.split()\n",
    "d1 = dict(zip(range(1, len(trainlist)+1), trainlist))\n",
    "d2 = dict(zip(trainlist, range(1, len(trainlist)+1)))\n",
    "vocab_size = len(d1) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenW(n):\n",
    "    try:\n",
    "        return d1[n]\n",
    "    except:\n",
    "        return ''\n",
    "def tokenN(s):\n",
    "    try:\n",
    "        return d2[s]\n",
    "    except:\n",
    "        return 0\n",
    "def tokenWL(nums):\n",
    "    words = \"\"\n",
    "    for i in range(len(nums)):\n",
    "        words += tokenW(nums[i]) + \" \"\n",
    "    return words\n",
    "def tokenNL(words):\n",
    "    ws = words.split()\n",
    "    ar = np.empty((len(ws),))\n",
    "    for i in range(len(ws)):\n",
    "        ar[i] = tokenN(ws[i])\n",
    "    return ar\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tokenNL(train)\n",
    "test_data = tokenNL(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19026786,)\n",
      "(2071994,)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator(object):\n",
    "    def __init__(self, data, num_steps, batch_size, total_words, skip_step=5):\n",
    "        self.data = data\n",
    "        self.num_steps = num_steps\n",
    "        self.batch_size = batch_size\n",
    "        self.total_words = total_words\n",
    "        self.current_idx = 0\n",
    "        self.skip_step = skip_step\n",
    "\n",
    "    def generate(self):\n",
    "        x = np.zeros((self.batch_size, self.num_steps))\n",
    "        y = np.zeros((self.batch_size, self.total_words))\n",
    "        while True:\n",
    "            for i in range(self.batch_size):\n",
    "                if self.current_idx + self.num_steps + 10 >= len(self.data):\n",
    "                    self.current_idx = (self.current_idx + self.num_steps + 10) % len(self.data)\n",
    "                x[i, :] = self.data[self.current_idx:self.current_idx + self.num_steps]\n",
    "                temp_y = self.data[self.current_idx + self.num_steps]\n",
    "                y[i, :] = tf.keras.utils.to_categorical(temp_y, num_classes=self.total_words)\n",
    "                self.current_idx += self.skip_step\n",
    "            yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_generator = BatchGenerator(train_data, 10, batch_size, vocab_size, skip_step=1000)\n",
    "test_data_generator = BatchGenerator(test_data, 10, batch_size, vocab_size, skip_step=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "well everyone got up and going this morning it's still - raining\n"
     ]
    }
   ],
   "source": [
    "x, y = next(train_data_generator.generate())\n",
    "print(tokenWL(x[0]), end=\"- \")\n",
    "print(tokenW(np.argmax(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yixuan/miniconda3/envs/mlgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yixuan/miniconda3/envs/mlgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yixuan/miniconda3/envs/mlgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yixuan/miniconda3/envs/mlgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yixuan/miniconda3/envs/mlgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 10, 128)           10126464  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 1024)              4722688   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 79113)             81090825  \n",
      "=================================================================\n",
      "Total params: 95,944,073\n",
      "Trainable params: 95,942,025\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/yixuan/miniconda3/envs/mlgpu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yixuan/miniconda3/envs/mlgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 128, input_length=10))\n",
    "model.add(LSTM(1024, return_sequences=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"checkpoints/weights-{epoch:02d}-{val_loss:.3f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1,\n",
    "    save_best_only=True, mode='auto', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yixuan/miniconda3/envs/mlgpu/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/3\n",
      "1161/1161 [==============================] - 130s 112ms/step - loss: 7.3445 - acc: 0.0751 - val_loss: 7.7033 - val_acc: 0.0637\n",
      "Epoch 2/3\n",
      "1161/1161 [==============================] - 127s 109ms/step - loss: 6.6728 - acc: 0.0966 - val_loss: 8.5240 - val_acc: 0.0281\n",
      "Epoch 3/3\n",
      "1161/1161 [==============================] - 128s 110ms/step - loss: 6.5760 - acc: 0.1070 - val_loss: 6.7244 - val_acc: 0.0820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7c2f85f590>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit network\n",
    "model.fit_generator(\n",
    "    generator=train_data_generator.generate(),\n",
    "    steps_per_epoch=len(train_data)//(batch_size)//256,\n",
    "    epochs=3,\n",
    "    validation_data=test_data_generator.generate(),\n",
    "    validation_steps = len(test_data)//(batch_size)//256,\n",
    "    #callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I wish you are not sure you want to get my own life so much like i want to do you want to get a much time i want to get it but i have heard of my life i want to get like this i want to get to work and i like have to be able to get out of a new time i would have been much of this morning i would have like i'm glad i want to see the time i just want to do about what i want to get a lot of days and i'm"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "generate_seq(model, 10, \"I wish\", 0.4, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
